import streamlit as st
import pandas as pd
import json
from datetime import datetime
from typing import List, Dict, Any, Union, Optional

# Import project modules
from config import app_config, ga_config
from ga_core.engine import run_ga_optimization
from ga_core import chromosome
from utils.helpers import convert_schedule_to_dataframe, parse_blocked_times, create_gantt_chart

# --- Helper functions for session state and data conversion ---

def string_to_date_obj(date_str: Optional[str]) -> Optional[datetime.date]:
    """Converts an ISO format string to a datetime.date object, returns None if invalid."""
    if not date_str or not isinstance(date_str, str):
        return None
    try:
        return datetime.fromisoformat(date_str.split('T')[0]).date()
    except (ValueError, TypeError):
        return None

def initialize_session_state() -> None:
    """Initializes the session state for storing tasks and app state if it doesn't exist."""
    if 'tasks' not in st.session_state:
        st.session_state.tasks: List[Dict[str, Any]] = [
            {"id": 1, "name": "So·∫°n b√°o c√°o DSS", "estimated_time_hr": 1.0, "priority": 1, "category": "C√¥ng vi·ªác",
             "predecessor_task_id": None, "deadline": "2025-08-04", "earliest_start_time": "2025-07-25"}
        ]
    
    if 'active_data_source' not in st.session_state:
        st.session_state.active_data_source: str = 'sample' # 'sample', 'upload', or 'manual'
    
    if 'uploaded_tasks' not in st.session_state:
        st.session_state.uploaded_tasks: Optional[List[Dict[str, Any]]] = None

def add_task() -> None:
    """Adds a new, empty task and sets the data source to manual."""
    max_id = max([task['id'] for task in st.session_state.tasks] or [0])
    new_task_id = max_id + 1
    st.session_state.tasks.append({
        "id": new_task_id, "name": "", "estimated_time_hr": 1.0, "priority": 3, "category": "",
        "predecessor_task_id": None, "deadline": None, "earliest_start_time": None
    })
    # <<< FIX: Set the active source to manual on interaction to prevent data loss
    st.session_state.active_data_source = 'manual'

def delete_task(task_id_to_delete: int) -> None:
    """Deletes a task and sets the data source to manual."""
    st.session_state.tasks = [
        task for task in st.session_state.tasks if task['id'] != task_id_to_delete
    ]
    # <<< FIX: Set the active source to manual on interaction to prevent data loss
    st.session_state.active_data_source = 'manual'
    
def set_source_to_manual() -> None:
    """Sets the active data source to manual when the 'Use' button is clicked."""
    st.session_state.active_data_source = 'manual'

# --- Main App Function ---

def main() -> None:
    """
    Main function to run the Streamlit application.
    """
    st.set_page_config(layout="wide")
    st.title("L·∫≠p L·ªãch C√¥ng Vi·ªác Tu·∫ßn B·∫±ng Thu·∫≠t To√°n Di Truy·ªÅn")

    initialize_session_state()

    # --- Sidebar for GA configuration ---
    # st.sidebar.header("C·∫•u h√¨nh Thu·∫≠t to√°n")
    
    # <<< FIX: Create a placeholder at the top of the sidebar for status messages
    status_placeholder = st.sidebar.empty()

    st.sidebar.subheader("Th√¥ng s·ªë Thu·∫≠t to√°n")
    ga_config.POPULATION_SIZE = st.sidebar.slider(
        "K√≠ch th∆∞·ªõc qu·∫ßn th·ªÉ (Population Size)", 10, 500, ga_config.POPULATION_SIZE, 10
    )
    ga_config.N_GENERATIONS = st.sidebar.slider(
        "S·ªë th·∫ø h·ªá (Generations)", 10, 1000, ga_config.N_GENERATIONS, 10
    )
    ga_config.MUTATION_PROBABILITY = st.sidebar.slider(
        "T·ª∑ l·ªá ƒë·ªôt bi·∫øn (Mutation Probability)", 0.01, 1.0, ga_config.MUTATION_PROBABILITY, 0.01
    )
    ga_config.CROSSOVER_PROBABILITY = st.sidebar.slider(
        "T·ª∑ l·ªá lai gh√©p (Crossover Probability)", 0.1, 1.0, ga_config.CROSSOVER_PROBABILITY, 0.05
    )
    ga_config.ELITE_SIZE = st.sidebar.slider(
        "Elite Size (how many top solutions to keep)", 1, 10, int(ga_config.POPULATION_SIZE * 0.1), 1
    )
    
    st.sidebar.subheader("R√†ng bu·ªôc Th·ªùi gian")
    blocked_times_str = st.sidebar.text_area(
        "Khung gi·ªù b·∫≠n", value=app_config.DEFAULT_BLOCKED_TIMES, height=200
    )
    
    try:
        blocked_slots = parse_blocked_times(blocked_times_str)
    except Exception as e:
        st.sidebar.error(f"L·ªói x·ª≠ l√Ω khung gi·ªù b·∫≠n: {e}")
        st.stop()

    # --- Main Screen Area ---
    st.header("T√πy ch·ªçn Nh·∫≠p li·ªáu C√¥ng vi·ªác")
    
    input_tab1, input_tab2 = st.tabs(["T·∫£i l√™n t·ªáp JSON", "Nh·∫≠p th·ªß c√¥ng"])

    with input_tab1:
        # st.subheader("1. T·∫£i l√™n t·ªáp JSON")
        uploaded_file = st.file_uploader(
            "T·∫£i l√™n t·ªáp JSON ch·ª©a c√°c c√¥ng vi·ªác", type=["json"], label_visibility="collapsed"
        )
        if uploaded_file is not None:
            # When a new file is uploaded, set it as the active source
            st.session_state.active_data_source = 'upload'
            try:
                # We need to seek back to the beginning of the file for re-reads
                uploaded_file.seek(0)
                st.session_state.uploaded_tasks = json.load(uploaded_file)
            except (json.JSONDecodeError, KeyError) as e:
                st.sidebar.error(f"L·ªói ƒë·ªçc t·ªáp: {e}")
                st.session_state.active_data_source = 'sample'
                st.stop()

    with input_tab2:
        # st.subheader("2. Ho·∫∑c Nh·∫≠p C√¥ng vi·ªác Th·ªß c√¥ng")

        header_cols = st.columns([0.5, 3, 1.5, 1, 2, 1.5, 1.5, 1.5, 0.5])
        header_cols[0].markdown("**ID**")
        header_cols[1].markdown("**T√™n c√¥ng vi·ªác**")
        header_cols[2].markdown("**Th·ªùi gian (h)**")
        header_cols[3].markdown("**∆Øu ti√™n**")
        header_cols[4].markdown("**Danh m·ª•c**")
        header_cols[5].markdown("**Vi·ªác ti√™n quy·∫øt**")
        header_cols[6].markdown("**Deadline**")
        header_cols[7].markdown("**B·∫Øt ƒë·∫ßu s·ªõm nh·∫•t**")
        header_cols[8].markdown("**X√≥a**")
        # st.divider()

        all_task_ids = [task['id'] for task in st.session_state.tasks]

        for task in st.session_state.tasks:
            cols = st.columns([0.5, 3, 1.5, 1, 2, 1.5, 1.5, 1.5, 0.5])
            
            cols[0].write(f"#{task['id']}")
            task['name'] = cols[1].text_input("Name", value=task["name"], key=f"name_{task['id']}", label_visibility="collapsed")
            task['estimated_time_hr'] = cols[2].number_input("Time (hr)", value=float(task["estimated_time_hr"]), min_value=0.5, step=0.5, format="%.1f", key=f"time_{task['id']}", label_visibility="collapsed")
            task['priority'] = cols[3].selectbox("Priority", options=[1, 2, 3], index=task["priority"] - 1, key=f"priority_{task['id']}", label_visibility="collapsed")
            task['category'] = cols[4].text_input("Category", value=task["category"], key=f"category_{task['id']}", label_visibility="collapsed")

            predecessor_options = [None] + [tid for tid in all_task_ids if tid != task['id']]
            current_predecessor_index = predecessor_options.index(task['predecessor_task_id']) if task['predecessor_task_id'] in predecessor_options else 0
            task['predecessor_task_id'] = cols[5].selectbox("Predecessor", options=predecessor_options, index=current_predecessor_index, key=f"pred_{task['id']}", label_visibility="collapsed")

            deadline_date_obj = cols[6].date_input("Deadline", value=string_to_date_obj(task["deadline"]), key=f"deadline_{task['id']}", label_visibility="collapsed")
            task['deadline'] = f"{deadline_date_obj.isoformat()}T23:59:59" if deadline_date_obj else None

            estart_date_obj = cols[7].date_input("Earliest Start", value=string_to_date_obj(task["earliest_start_time"]), key=f"estart_{task['id']}", label_visibility="collapsed")
            task['earliest_start_time'] = f"{estart_date_obj.isoformat()}T00:00:00" if estart_date_obj else None

            cols[8].button("üóëÔ∏è", key=f"delete_{task['id']}", on_click=delete_task, args=(task['id'],))

        st.divider()
        
        # st.button("+ Th√™m c√¥ng vi·ªác m·ªõi", on_click=add_task, use_container_width=True)
        col1, col2 = st.columns(2)
        with col1:
            st.button("+ Th√™m c√¥ng vi·ªác m·ªõi", on_click=add_task, use_container_width=True)
        with col2:
            st.button("S·ª≠ d·ª•ng c√°c c√¥ng vi·ªác ƒë√£ nh·∫≠p", type="primary", use_container_width=True, on_click=set_source_to_manual)

    # --- Task Loading Logic ---
    tasks: Optional[List[Dict[str, Any]]] = None
    final_tasks_for_ga: List[Dict[str, Any]] = []
    
    # <<< FIX: Determine the status message based on the active data source
    status_message: str = ""
    status_type: str = "info"

    # <<< FIX: The main logic now reads from the session state flag
    if st.session_state.active_data_source == 'upload' and st.session_state.uploaded_tasks:
        tasks = st.session_state.uploaded_tasks
        status_message = f"ƒêang s·ª≠ d·ª•ng {len(tasks)} c√¥ng vi·ªác t·ª´ t·ªáp ƒë√£ t·∫£i l√™n!"
        status_type = "success"
    elif st.session_state.active_data_source == 'manual':
        tasks = st.session_state.tasks
        status_message = f"ƒêang s·ª≠ d·ª•ng {len(tasks)} c√¥ng vi·ªác nh·∫≠p th·ªß c√¥ng!"
        status_type = "success"
    else: # Default to 'sample'
        status_message = "S·ª≠ d·ª•ng d·ªØ li·ªáu m·∫´u. H√£y t·∫£i t·ªáp l√™n ho·∫∑c nh·∫≠p th·ªß c√¥ng."
        status_type = "info"
        try:
            with open("./data/sample_tasks.json", 'r', encoding='utf-8') as f:
                tasks = json.load(f)
        except (json.JSONDecodeError, KeyError, FileNotFoundError) as e:
            st.sidebar.error(f"L·ªói ƒë·ªçc t·ªáp m·∫´u: {e}")
            st.stop()

    # <<< FIX: Populate the placeholder with the determined message
    if status_type == "success":
        status_placeholder.success(status_message)
    else:
        status_placeholder.info(status_message)

    # --- Final Task Processing and Display ---
    if tasks:
        for task in tasks:
            processed_task = task.copy()
            time_in_hours = processed_task.pop('estimated_time_hr', task.get('estimated_time'))
            if time_in_hours is not None:
                try:
                    slots = int(float(time_in_hours) * 60 / app_config.TIME_SLOT_DURATION)
                    processed_task['estimated_time'] = max(1, slots)
                except (ValueError, TypeError):
                    processed_task['estimated_time'] = 1
            
            for key in ['predecessor_task_id', 'deadline', 'earliest_start_time']:
                if not processed_task.get(key):
                    processed_task[key] = None
            final_tasks_for_ga.append(processed_task)
        
        st.header("C√°c c√¥ng vi·ªác c·∫ßn s·∫Øp x·∫øp")
        st.dataframe(pd.DataFrame(final_tasks_for_ga), use_container_width=True)
    
        if st.button("T·∫°o L·ªãch Tr√¨nh", type="primary", use_container_width=True):
            if final_tasks_for_ga:
                with st.spinner("Thu·∫≠t to√°n di truy·ªÅn ƒëang t√≠nh to√°n..."):
                    
                    task_instances: List[Dict[str, Any]] = []
                    for i, task_data in enumerate(final_tasks_for_ga):
                        instance = task_data.copy()
                        instance['instance_id'] = f"task_{i}"
                        instance['original_id'] = task_data.get('id', i)
                        task_instances.append(instance)
                    
                    tasks_map: Dict[str, Dict[str, Any]] = {task['instance_id']: task for task in task_instances}

                    progress_bar = st.progress(0.0, text="B·∫Øt ƒë·∫ßu...")
                    status_text = st.empty()
                    
                    def progress_callback(progress_value: float, message: str) -> None:
                        progress_bar.progress(progress_value)
                        status_text.text(message)

                    best_individual, logbook = run_ga_optimization(
                        tasks_map=tasks_map,
                        task_instances=task_instances,
                        blocked_slots=blocked_slots,
                        progress_callback=progress_callback
                    )

                    st.header("ƒê√£ t√¨m th·∫•y l·ªãch tr√¨nh t·ªëi ∆∞u")
                    
                    final_schedule = best_individual[0]
                    final_fitness = final_schedule.fitness.values[0]

                    col1, col2, col3 = st.columns(3)
                    col1.metric("ƒêi·ªÉm Fitness cu·ªëi c√πng", f"{final_fitness:,.0f}")
                    col2.metric("T·ªïng s·ªë c√¥ng vi·ªác", f"{len(final_schedule)}")
                    col3.metric("S·ªë th·∫ø h·ªá", f"{ga_config.N_GENERATIONS}")

                    if not final_schedule or final_fitness == 0.0:
                        st.warning("Kh√¥ng t√¨m th·∫•y l·ªãch tr√¨nh h·ª£p l·ªá. H√£y th·ª≠ tƒÉng s·ªë th·∫ø h·ªá, k√≠ch th∆∞·ªõc qu·∫ßn th·ªÉ, ho·∫∑c ƒëi·ªÅu ch·ªânh c√°c r√†ng bu·ªôc.")
                    else:
                        schedule_df = convert_schedule_to_dataframe(final_schedule, tasks_map)
                        
                        fig = create_gantt_chart(schedule_df)
                        st.plotly_chart(fig, use_container_width=True)

                        st.subheader("Chi ti·∫øt L·ªãch tr√¨nh")
                        st.dataframe(schedule_df.sort_values(by="Start").reset_index(drop=True), use_container_width=True)
                        
                        st.subheader("Logbook Chi ti·∫øt")
                        log_df = pd.DataFrame(logbook)
                        log_df = log_df[['gen', 'avg', 'min', 'max']]
                        st.dataframe(log_df, use_container_width=True)
            else:
                st.warning("Kh√¥ng c√≥ c√¥ng vi·ªác n√†o ƒë·ªÉ s·∫Øp x·∫øp. Vui l√≤ng t·∫£i t·ªáp l√™n ho·∫∑c nh·∫≠p th·ªß c√¥ng.")

if __name__ == "__main__":
    main()